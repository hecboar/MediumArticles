{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55zkfxTLDrJV"
      },
      "source": [
        "```mermaid\n",
        "graph TD;\n",
        "    A[User Input] -->|Input Moderation| B{Is Input Allowed?};\n",
        "    B -- Yes --> C[Dialog Constraints];\n",
        "    B -- No --> D[Reject Input];\n",
        "    C -->|Execute Actions| E[Custom Actions];\n",
        "    E -->|Retrieve Data| F[Context Retrieval];\n",
        "    F --> G[Response Generation];\n",
        "    G -->|Output Validation| H{Is Output Valid?};\n",
        "    H -- Yes --> I[Send Response];\n",
        "    H -- No --> J[Modify/Reject Response];\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rSbdrweD0yA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **Complete Configuration of NeMo Guardrails**\n",
        "\n",
        "**NeMo Guardrails** allows customization of how an **LLM-based system** manages inputs, dialogues, and outputs. Below is a detailed explanation of each configuration component and its purpose.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Configuration Components**\n",
        "\n",
        "##### **1. Input Moderation**\n",
        "Controls user inputs to ensure they are safe and appropriate.\n",
        "\n",
        "- **What does it do?**\n",
        "  - Blocks offensive language, inappropriate questions, or manipulation attempts.\n",
        "  - Ensures that only valid queries are processed.\n",
        "\n",
        "- **Example (Colang format):**\n",
        "```colang\n",
        "define user express_insult\n",
        "  \"You are stupid\"\n",
        "  \"I want to harm you\"\n",
        "\n",
        "```\n",
        "\n",
        "define flow handle_insult\n",
        "  user express_insult\n",
        "  bot express_calmly_willingness_to_help\n",
        "```\n",
        "\n",
        "\n",
        "##### **2. Dialog Constraints**\n",
        "\n",
        "\n",
        "Structures and manages conversational flows between the user and the bot.\n",
        "\n",
        "- **What does it do?**\n",
        " - Defines how the bot responds to different user intentions.\n",
        " - Establishes rules for handling queries, retrieving context, and generating responses.\n",
        "\n",
        "- **Example (Colang format):**\n",
        "\n",
        "```colang\n",
        "define user ask_question\n",
        "    \"What is the capital of France?\"\n",
        "    \"What is the weather today?\"\n",
        "\n",
        "define flow handle_general_input\n",
        "    user ask_question\n",
        "    $contexts = execute retrieve(query=$last_user_message)\n",
        "    $answer = execute rag(query=$last_user_message, contexts=$contexts)\n",
        "    bot $answer\n",
        "```\n",
        "\n",
        "##### **3. Output Validation**\n",
        "\n",
        "Validates generated responses before sending them to the user\n",
        "\n",
        "- **What does it do**\n",
        "\n",
        " - Checks that the response is consistent with the context.\n",
        " - Removes false or inappropriate responses.\n",
        "\n",
        "- **Example (Colang format):**\n",
        "```colang\n",
        "define flow validate_response\n",
        "    $accurate = execute check_facts(evidence_list=$contexts)\n",
        "    if not $accurate:\n",
        "        bot remove last message\n",
        "        bot \"I couldn't find a reliable answer to your question.\"\n",
        "```\n",
        "\n",
        "##### **4. config.yml File**\n",
        "\n",
        "Configures the system's main models and parameters.\n",
        "\n",
        "- **What does it do?**\n",
        "\n",
        " - Defines the LLM model, the engine (OpenAI or others), and parameters such as temperature.\n",
        "\n",
        "- **Example (Colang format):**\n",
        "\n",
        "```yaml\n",
        "models:\n",
        "- type: main\n",
        "  engine: openai\n",
        "  model: gpt-3.5-turbo\n",
        "  parameters:\n",
        "    temperature: 0.1\n",
        "```\n",
        "##### **5.co (Colang) File**\n",
        "\n",
        "Defines the rules and interaction flows between the user and the bot.\n",
        "\n",
        "- **What does it do?**\n",
        "\n",
        " - Specifies user expressions, bot responses, and actions to execute.\n",
        "\n",
        "- **Structure**\n",
        "\n",
        " - User Expressions: Identifies user intentions.\n",
        " - Bot Responses: Defines how the bot should respond.\n",
        " - Flows: Links user inputs to responses and actions.\n",
        "\n",
        "##### **6. Custom Actions**\n",
        "\n",
        "Allows integration of custom logic or querying external systems.\n",
        "\n",
        "- **What are they?**\n",
        "\n",
        " -Python functions that extend the bot’s capabilities.\n",
        "\n",
        " -Registered in NeMo Guardrails for use in dialogue flows.\n",
        "\n",
        "- **What do they do?**\n",
        "\n",
        " -Retrieve data, generate summaries, or validate facts.\n",
        "\n",
        " -Executed via execute.\n",
        "\n",
        "\n",
        "- **Example (Python format):**\n",
        " ```python\n",
        "from nemoguardrails.actions.actions import action\n",
        "@action(name=\"retrieve\")\n",
        "async def retrieve(query: str) -> list:\n",
        "    # Retrieve relevant context from a database or vector store\n",
        "    results = index.similarity_search(query, k=5)\n",
        "    return [doc.text for doc in results]\n",
        "@action(name=\"summarize_document\")\n",
        "async def summarize_document(document: str) -> str:\n",
        "    # Generate a summary for a given document\n",
        "    prompt = f\"Summarize the following document:\\n\\n{document}\"\n",
        "    return get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
        " ```\n",
        "\n",
        "##### **Action Registration**\n",
        "\n",
        "Registers actions so they can be used in flows.\n",
        "\n",
        "\n",
        "- **Example (Python format):**\n",
        "\n",
        "```python\n",
        "from nemoguardrails import LLMRails, RailsConfig\n",
        "\n",
        "config = RailsConfig.from_content(yaml_content=yaml_content, colang_content=colang_content)\n",
        "rails = LLMRails(config)\n",
        "\n",
        "print(\"NeMo Guardrails successfully configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8-xi0arqyWv"
      },
      "source": [
        "#Setup dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gklZSS1rDhSB",
        "outputId": "822df1c2-d141-4f45-be14-8e9b7b6a78e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nemoguardrails\n",
            "  Downloading nemoguardrails-0.11.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.0)\n",
            "Collecting docling\n",
            "  Downloading docling-2.18.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (3.11.11)\n",
            "Collecting annoy>=1.17.3 (from nemoguardrails)\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastapi>=0.103.0 (from nemoguardrails)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting fastembed<0.4.1,>=0.2.2 (from nemoguardrails)\n",
            "  Downloading fastembed-0.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting httpx<0.25.0,>=0.24.1 (from nemoguardrails)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (3.1.5)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.2.14 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (0.3.17)\n",
            "Collecting langchain-community<0.4.0,>=0.0.16 (from nemoguardrails)\n",
            "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.2.14 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (0.3.33)\n",
            "Collecting lark<1.2.0,>=1.1.7 (from nemoguardrails)\n",
            "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (1.6.0)\n",
            "Collecting onnxruntime<2.0.0,>=1.17.0 (from nemoguardrails)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "  Downloading onnxruntime-1.19.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (2.2.2)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (3.0.50)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (2.10.6)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (6.0.2)\n",
            "Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (13.9.4)\n",
            "Collecting simpleeval>=0.9.13 (from nemoguardrails)\n",
            "  Downloading simpleeval-1.0.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting starlette>=0.27.0 (from nemoguardrails)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: typer>=0.8 in /usr/local/lib/python3.11/dist-packages (from nemoguardrails) (0.15.1)\n",
            "Collecting uvicorn>=0.23 (from nemoguardrails)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting watchdog>=3.0.0 (from nemoguardrails)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from docling) (4.13.1)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from docling) (2025.1.31)\n",
            "Collecting deepsearch-glm<2.0.0,>=1.0.0 (from docling)\n",
            "  Downloading deepsearch_glm-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting docling-core<3.0.0,>=2.17.0 (from docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading docling_core-2.17.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting docling-ibm-models<4.0.0,>=3.3.0 (from docling)\n",
            "  Downloading docling_ibm_models-3.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting docling-parse<4.0.0,>=3.1.0 (from docling)\n",
            "  Downloading docling_parse-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting easyocr<2.0,>=1.7 (from docling)\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.11/dist-packages (from docling) (0.28.1)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from docling) (5.3.0)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.1.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from docling) (3.1.5)\n",
            "Collecting pillow<11.0.0,>=10.0.0 (from docling)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pypdfium2<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from docling) (2.32.3)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from docling) (1.13.1)\n",
            "Collecting typer>=0.8 (from nemoguardrails)\n",
            "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.2.14 (from nemoguardrails)\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->nemoguardrails) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.6)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (4.23.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (0.9.0)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from docling-core[chunking]<3.0.0,>=2.17.0->docling) (4.48.2)\n",
            "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (4.11.0.86)\n",
            "Requirement already satisfied: safetensors<1,>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.3.0->docling) (0.5.2)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.11/dist-packages (from docling-ibm-models<4.0.0,>=3.3.0->docling) (0.20.1+cu124)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.1)\n",
            "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr<2.0,>=1.7->docling) (2.0.7)\n",
            "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting PyStemmer<3.0.0,>=2.2.0 (from fastembed<0.4.1,>=0.2.2->nemoguardrails)\n",
            "  Downloading PyStemmer-2.2.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed<0.4.1,>=0.2.2->nemoguardrails)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from fastembed<0.4.1,>=0.2.2->nemoguardrails)\n",
            "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from fastembed<0.4.1,>=0.2.2->nemoguardrails)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: snowballstemmer<3.0.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from fastembed<0.4.1,>=0.2.2->nemoguardrails) (2.2.0)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from fastembed<0.4.1,>=0.2.2->nemoguardrails) (0.21.0)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx<0.25.0,>=0.24.1->nemoguardrails)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.5->nemoguardrails) (3.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (2.0.37)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (0.3.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.2.14->nemoguardrails) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.0.16->nemoguardrails)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community<0.4.0,>=0.0.16->nemoguardrails)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.2.14->nemoguardrails) (1.33)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (3.4.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.11-py3-none-any.whl.metadata (912 bytes)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->nemoguardrails)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.17.0->nemoguardrails) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.17.0->nemoguardrails) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2.0.0,>=1.17.0->nemoguardrails) (1.13.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->nemoguardrails) (2025.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit>=3.0->nemoguardrails) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->nemoguardrails) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->nemoguardrails) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nemoguardrails) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nemoguardrails) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.8->nemoguardrails) (1.5.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23->nemoguardrails) (0.14.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.0.16->nemoguardrails)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.2.14->nemoguardrails) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.17.0->docling-core[chunking]<3.0.0,>=2.17.0->docling) (0.22.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.2.14->nemoguardrails) (0.23.0)\n",
            "Collecting certifi>=2024.7.4 (from docling)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting llama-cloud-services (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nemoguardrails) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->nemoguardrails) (1.17.0)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.2.14->nemoguardrails) (3.1.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.3.0->docling) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->nemoguardrails) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->nemoguardrails)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Collecting multiprocess>=0.70.15 (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting dill>=0.3.9 (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.17.0->docling)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading nemoguardrails-0.11.1-py3-none-any.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n",
            "Downloading docling-2.18.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepsearch_glm-1.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.17.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.3.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-3.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastembed-0.4.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.4.3-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_llms_openai-0.3.18-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.4-py3-none-any.whl (39 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading marko-2.1.2-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (543 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simpleeval-1.0.3-py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_cloud-0.1.11-py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.0-py3-none-any.whl (4.8 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyStemmer-2.2.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.3/669.3 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading llama_cloud_services-0.6.0-py3-none-any.whl (22 kB)\n",
            "Downloading multiprocess-0.70.17-py311-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-linux_x86_64.whl size=551658 sha256=2069f64f8eb0a8340be47032e039a1d28b1c305b1d3bc15572695410d837c12d\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/e5/58/0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\n",
            "Successfully built annoy\n",
            "Installing collected packages: striprtf, python-bidi, PyStemmer, pyclipper, mmh3, filetype, dirtyjson, annoy, XlsxWriter, watchdog, uvicorn, simpleeval, rtree, python-dotenv, python-docx, pypdfium2, pypdf, pillow, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, mypy-extensions, mpire, marshmallow, marko, loguru, latex2mathml, lark, jsonref, jsonlines, humanfriendly, httpx-sse, dill, deepsearch-glm, certifi, typing-inspect, starlette, python-pptx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, coloredlogs, typer, tiktoken, pydantic-settings, onnxruntime, nvidia-cusolver-cu12, httpx, fastapi, dataclasses-json, semchunk, llama-index-core, llama-cloud, docling-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langchain-core, fastembed, docling-parse, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain-openai, easyocr, docling-ibm-models, llama-index-readers-llama-parse, llama-index-program-openai, docling, llama-index-question-gen-openai, langchain-community, nemoguardrails, llama-index\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.1\n",
            "    Uninstalling typer-0.15.1:\n",
            "      Successfully uninstalled typer-0.15.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "Successfully installed PyStemmer-2.2.0.3 XlsxWriter-3.2.2 annoy-1.17.3 certifi-2024.12.14 coloredlogs-15.0.1 dataclasses-json-0.6.7 deepsearch-glm-1.0.0 dill-0.3.9 dirtyjson-1.0.8 docling-2.18.0 docling-core-2.17.2 docling-ibm-models-3.3.1 docling-parse-3.3.0 easyocr-1.7.2 fastapi-0.115.8 fastembed-0.4.0 filetype-1.2.0 httpcore-0.17.3 httpx-0.24.1 httpx-sse-0.4.0 humanfriendly-10.0 jsonlines-3.1.0 jsonref-1.1.0 langchain-community-0.3.16 langchain-core-0.3.34 langchain-openai-0.3.4 lark-1.1.9 latex2mathml-3.77.0 llama-cloud-0.1.11 llama-cloud-services-0.6.0 llama-index-0.12.16 llama-index-agent-openai-0.4.3 llama-index-cli-0.4.0 llama-index-core-0.12.16.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.18 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.4 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.0 loguru-0.7.3 marko-2.1.2 marshmallow-3.26.1 mmh3-4.1.0 mpire-2.10.2 multiprocess-0.70.17 mypy-extensions-1.0.0 nemoguardrails-0.11.1 ninja-1.11.1.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 onnxruntime-1.19.2 pillow-10.4.0 pyclipper-1.3.0.post6 pydantic-settings-2.7.1 pypdf-5.2.0 pypdfium2-4.30.1 python-bidi-0.6.3 python-docx-1.1.2 python-dotenv-1.0.1 python-pptx-1.0.2 rtree-1.3.0 semchunk-2.2.2 simpleeval-1.0.3 starlette-0.45.3 striprtf-0.0.26 tiktoken-0.8.0 typer-0.12.5 typing-inspect-0.9.0 uvicorn-0.34.0 watchdog-6.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi"
                ]
              },
              "id": "8e06cd40bf9d4ec9b7026c25e5bbe61d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install nemoguardrails llama-index openai docling langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download the document"
      ],
      "metadata": {
        "id": "66MQarjQuIsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget -O CraneManual.pdf \"https://silvatech.pl/wp-content/uploads/2013/07/New-book-Crane-Great-Britain.pdf\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orUjNvfpwZiH",
        "outputId": "e7de6cc8-2b20-4230-cfed-d14733b9e2e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-07 08:05:47--  https://silvatech.pl/wp-content/uploads/2013/07/New-book-Crane-Great-Britain.pdf\n",
            "Resolving silvatech.pl (silvatech.pl)... 79.96.48.114\n",
            "Connecting to silvatech.pl (silvatech.pl)|79.96.48.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5284022 (5.0M) [application/pdf]\n",
            "Saving to: ‘CraneManual.pdf’\n",
            "\n",
            "CraneManual.pdf     100%[===================>]   5.04M  3.75MB/s    in 1.3s    \n",
            "\n",
            "2025-02-07 08:05:49 (3.75 MB/s) - ‘CraneManual.pdf’ saved [5284022/5284022]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parser with docling and convert to LlamaIndex nodes (Vector Store Index)"
      ],
      "metadata": {
        "id": "3ehDKK6OwZPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Torch device count:\", torch.cuda.device_count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNLsFoYixxVN",
        "outputId": "9b352fb5-ca19-458a-f10c-56b4efbe07a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "CUDA available: True\n",
            "Torch device count: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'YOUR_OPEN_API'"
      ],
      "metadata": {
        "id": "t8Ju6fOEy1Hp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from docling.document_converter import DocumentConverter\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# Global embedding model for LlamaIndex\n",
        "Settings.embed_model = OpenAIEmbedding()\n",
        "\n",
        "class CraneManualProcessor:\n",
        "    def __init__(self, source_pdf):\n",
        "        \"\"\"\n",
        "        Converts the PDF into structured nodes for retrieval.\n",
        "        \"\"\"\n",
        "        self.source_pdf = str(Path(source_pdf).resolve())\n",
        "        self.base_name = str(Path(source_pdf).with_suffix('').resolve())\n",
        "\n",
        "    # Step 1: Convert PDF to Markdown using Docling\n",
        "    def convert_pdf_to_markdown(self):\n",
        "        \"\"\"Uses Docling to extract structured content from the PDF.\"\"\"\n",
        "        converter = DocumentConverter()\n",
        "        result = converter.convert(self.source_pdf)\n",
        "        md_content = result.document.export_to_markdown()\n",
        "\n",
        "        markdown_path = f\"{self.base_name}_content.md\"\n",
        "        with open(markdown_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(md_content)\n",
        "\n",
        "        print(f\"✅ Markdown saved: {markdown_path}\")\n",
        "        return md_content\n",
        "\n",
        "    # Step 2: Split Markdown by Sections and Subsections\n",
        "    def split_markdown_by_sections(self, md_content, min_length=1024):\n",
        "        \"\"\"\n",
        "        Splits the markdown content using heading markers (#, ##, ###) while ensuring\n",
        "        that each section has at least `min_length` characters before further splitting.\n",
        "        \"\"\"\n",
        "        lines = md_content.split(\"\\n\")\n",
        "        sections = []\n",
        "        current_section = []\n",
        "        current_text = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().startswith(\"#\"):  # Detect section headers\n",
        "                if current_text and len(current_text) >= min_length:\n",
        "                    sections.append(current_text.strip())  # Save previous section\n",
        "                    current_text = \"\"\n",
        "\n",
        "                current_section = [line]  # Start new section\n",
        "\n",
        "            else:\n",
        "                current_section.append(line)\n",
        "\n",
        "            current_text = \"\\n\".join(current_section)  # Combine lines\n",
        "\n",
        "        # Ensure last section is added\n",
        "        if current_text:\n",
        "            sections.append(current_text.strip())\n",
        "\n",
        "        print(f\"✅ Split document into {len(sections)} sections.\")\n",
        "        return sections\n",
        "\n",
        "    # Step 3: Convert Sections to LlamaIndex Nodes\n",
        "    def convert_sections_to_nodes(self, sections):\n",
        "        \"\"\"\n",
        "        Converts each structured section into LlamaIndex document nodes.\n",
        "        \"\"\"\n",
        "        doc_nodes = [Document(text=section) for section in sections]\n",
        "        print(f\"✅ Created {len(doc_nodes)} document nodes for LlamaIndex.\")\n",
        "        return doc_nodes\n",
        "\n",
        "    # Step 4: Index Nodes into LlamaIndex\n",
        "    def index_nodes(self, doc_nodes):\n",
        "        \"\"\"\n",
        "        Creates a vector index for efficient retrieval using LlamaIndex.\n",
        "        \"\"\"\n",
        "        # Create an in-memory vector index\n",
        "        index = VectorStoreIndex.from_documents(doc_nodes)\n",
        "\n",
        "        # Save the index for later retrieval\n",
        "        index.storage_context.persist(persist_dir=f\"{self.base_name}_index\")\n",
        "\n",
        "        print(f\"✅ Indexed {len(doc_nodes)} sections into LlamaIndex.\")\n",
        "        return index\n",
        "\n",
        "    # Step 5: Run the full processing pipeline\n",
        "    def process(self):\n",
        "        md_content = self.convert_pdf_to_markdown()\n",
        "        sections = self.split_markdown_by_sections(md_content)\n",
        "        doc_nodes = self.convert_sections_to_nodes(sections)\n",
        "        index = self.index_nodes(doc_nodes)\n",
        "        return index\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    processor = CraneManualProcessor(\"CraneManual.pdf\")\n",
        "    index = processor.process()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duzTZgjEuJDu",
        "outputId": "ff99b01d-bde4-41e4-edf6-d887b41b95d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Markdown saved: /content/CraneManual_content.md\n",
            "✅ Split document into 16 sections.\n",
            "✅ Created 16 document nodes for LlamaIndex.\n",
            "✅ Indexed 16 sections into LlamaIndex.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the values"
      ],
      "metadata": {
        "id": "hDG5XGGNzoOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = list(index.docstore.docs.values())\n",
        "print(nodes[9].text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK-5iTz7zHww",
        "outputId": "7beec6ed-516f-4cf4-aeb5-c738121d25a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 4.6 Technical data, FARMA cranes\n",
            "\n",
            "|         |   Lifting  capacity,  net:  kNm |   Slewing  torque  kNm |   Slewing  angle   degrees |   Reach  m | Telescopic  stroke  length  m   | Recommended  flow  l/min   |   Working  pressure  bar | Weight kg  incl. 0.12  grapple*/ Weight of  crane   | Weight kg  incl. 0.16  grapple*/ Weight of  crane   | Weight kg  incl. 0.19  grapple*/ Weight of  crane   | Weight kg  incl. 0.20  grapple*/ Weight of  crane   | Weight kg  incl. 0.22  grapple*/ Weight of  crane   |   Lifting force  kg  full length  (excl. grapple  and rotator) |\n",
            "|---------|---------------------------------|------------------------|----------------------------|------------|---------------------------------|----------------------------|--------------------------|-----------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|----------------------------------------------------------------|\n",
            "| C 3.8   |                              22 |                    3   |                        360 |        3.8 | -                               | 10 - 35                    |                      175 | 371 300                                             | 392 300                                             | -                                                   | -                                                   | -                                                   |                                                            300 |\n",
            "| C 4.6S  |                              27 |                    4.4 |                        360 |        4.6 | -                               | 10 - 35                    |                      175 | -                                                   | 572 480                                             | 592 480                                             | 607 480                                             | -                                                   |                                                            480 |\n",
            "| C 4.6 D |                              27 |                    8.8 |                        360 |        4.6 | -                               | 10 - 35                    |                      175 | -                                                   | 602 510                                             | 622 510                                             | 637 510                                             | -                                                   |                                                            480 |\n",
            "| C 5.1   |                              33 |                    8.8 |                        360 |        5.1 | -                               | 35-50                      |                      175 | -                                                   | 622 530                                             | 642 530                                             | 657 530                                             | -                                                   |                                                            450 |\n",
            "| C 5.3   |                              33 |                    8.8 |                        360 |        5.3 | -                               | 35-50                      |                      175 | -                                                   | 672 580                                             | 692 580                                             | 707 580                                             | -                                                   |                                                            570 |\n",
            "| C 6.0   |                              33 |                    8.8 |                        360 |        6   | 0,9                             | 35-50                      |                      175 | -                                                   | 672 580                                             | 692 580                                             | 707 580                                             | -                                                   |                                                            390 |\n",
            "| C 6.3   |                              33 |                    8.8 |                        360 |        6.3 | 1,1                             | 35-50                      |                      175 | -                                                   | 722 630                                             | 742 630                                             | 757 630                                             | -                                                   |                                                            445 |\n",
            "| C 6.5   |                              44 |                   12   |                        360 |        6.5 | 1,1                             | 45-60                      |                      175 | -                                                   | -                                                   | -                                                   | -                                                   | 903 770                                             |                                                            625 |\n",
            "| C 8.5   |                              40 |                   16   |                        360 |        8.5 | 3                               | 45-60                      |                      175 | -                                                   | -                                                   | -                                                   | -                                                   | 903 770                                             |                                                            450 |\n",
            "\n",
            "-=   Not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create the query engine and reranker"
      ],
      "metadata": {
        "id": "Hn9S6rRc09gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
        "\n",
        "# Initialize reranker with top 5 candidates\n",
        "rerank = SentenceTransformerRerank(\n",
        "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", top_n=5\n",
        ")\n",
        "\n",
        "# Create query engine with reranker\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=10,  # Retrieve top 10 candidates first\n",
        "    node_postprocessors=[rerank]  # Apply reranking select 5 from 10\n",
        ")\n"
      ],
      "metadata": {
        "id": "hBL51a9Q1oeT"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query('What are the primary applications of FARMA cranes, and in which industries are they intended to be used?')"
      ],
      "metadata": {
        "id": "OuSQXQ9Wt8Fy"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CC3BWIMpuRn-",
        "outputId": "ab330f4d-53a1-4080-8700-8b31a0feea50"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The primary applications of FARMA cranes include handling round timber, fodder, fertiliser, sand, loose fertiliser, large sacks, and automatic timber transportation in forestry. These cranes are intended to be used in the fields of agriculture and forestry by individuals with knowledge about the handling of agricultural machinery.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NeMo GuardRails -->Building Custom Retrieval and RAG Actions"
      ],
      "metadata": {
        "id": "N_6HEA6f19ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create NeMo Guardrails custom actions\n"
      ],
      "metadata": {
        "id": "LLYwurbU16Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG Action"
      ],
      "metadata": {
        "id": "CYMYs2Pd2Kw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nemoguardrails.actions.actions import action\n",
        "\n",
        "@action(name=\"rag\")\n",
        "async def rag(query: str) -> list:\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)"
      ],
      "metadata": {
        "id": "Ee52bN7217MG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "nQGmlB3RQqck"
      },
      "outputs": [],
      "source": [
        "\n",
        "@action(name=\"escalate_to_industrial_system\")\n",
        "async def escalate_to_industrial_system(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Simulates escalation of non-crane-related industrial questions\n",
        "    to an external industrial system or human expert.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user's original question.\n",
        "\n",
        "    Returns:\n",
        "        str: Response indicating escalation has been processed.\n",
        "    \"\"\"\n",
        "    # Simulated escalation process\n",
        "    print(f\"[Escalation] Forwarding query to external industrial expert system: {query}\")\n",
        "\n",
        "    # Simulated external system response\n",
        "    external_response = f\"I have forwarded your request: '{query}'. A specialist will assist you shortly.\"\n",
        "\n",
        "    return external_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ypMxbIQuzd"
      },
      "source": [
        "### Configuring NeMo Guardrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "upkKitOyQ53v"
      },
      "outputs": [],
      "source": [
        "from nemoguardrails import LLMRails, RailsConfig\n",
        "\n",
        "yaml_content = \"\"\"\n",
        "models:\n",
        "- type: main\n",
        "  engine: openai\n",
        "  model: gpt-3.5-turbo\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v2T7KoRQ8kJ"
      },
      "source": [
        "### Creating the LLMRails Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "SZM-ALTYQ-1v"
      },
      "outputs": [],
      "source": [
        "from nemoguardrails import LLMRails, RailsConfig\n",
        "config = RailsConfig.from_content(yaml_content=yaml_content, colang_content=\"\")\n",
        "\n",
        "rails = LLMRails(config)\n",
        "\n",
        "# Register our custom actions\n",
        "#rails.register_action(action=retrieve, name=\"retrieve\")\n",
        "rails.register_action(action=rag, name=\"rag\")\n",
        "rails.register_action(escalate_to_industrial_system, \"escalate_to_industrial_system\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blEJiOCKRL1N"
      },
      "source": [
        "### Creating Guardrail Rules (Colang)\n",
        "\n",
        "Let’s define dialog flows and moderation rules:\n",
        "\n",
        "Catching Offensive or Unsafe Queries\n",
        "Ignoring Off-Topic Queries\n",
        "Responding to Crane-Related Questions\n",
        "In Colang, we define user expressions, bot responses, and flows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRecB5G8ROY_"
      },
      "source": [
        "**Example Colang File**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colang_content = \"\"\"\n",
        "# --- Welcome Message ---\n",
        "define flow welcome_message\n",
        "  bot \"Good morning, I am your assistant for crane installation, maintenance, and safety guidelines. Please ask me about setup procedures, troubleshooting, load capacities, or regulatory compliance.\"\n",
        "\n",
        "# --- Offensive / Unsafe Queries ---\n",
        "define user express_insult\n",
        "  \"You are stupid\"\n",
        "  \"I want to harm you\"\n",
        "  \"Go to hell\"\n",
        "  \"This is useless\"\n",
        "\n",
        "define bot respond_offensive\n",
        "  \"I am here to assist with crane-related topics. If you need help with installation or maintenance, please ask.\"\n",
        "\n",
        "define flow handle_insult\n",
        "  user express_insult\n",
        "  bot respond_offensive\n",
        "\n",
        "# --- Off-topic Queries ---\n",
        "define user ask_off_topic\n",
        "  \"How do I bake a cake?\"\n",
        "  \"What's the best soccer team?\"\n",
        "  \"Which team emerged as the winner in the latest F1 race?\"\n",
        "  \"Who won the last Formula 1 race?\"\n",
        "  \"Who won the last Formula 1 this year?\"\n",
        "  \"Who won the Formula 1 this year?\"\n",
        "  \"Who won the the Formula 1 this year?\"   // added to catch extra \"the\"\n",
        "  \"Who won the last F1 race?\"              // additional variant\n",
        "  \"Who is the Formula 1 winner?\"\n",
        "  \"Who won the latest Formula 1 race?\"\n",
        "  \"Who won the last NBA game?\"\n",
        "  \"Which team won the most recent NFL matchup?\"\n",
        "  \"Who came out on top in the last MLB game?\"\n",
        "  \"Which club won the latest English Premier League match?\"\n",
        "  \"Who was the victor in the most recent NHL game?\"\n",
        "  \"Which team secured the win in the last UEFA Champions League match?\"\n",
        "  \"Who won the latest tennis match at the US Open?\"\n",
        "  \"latest formula 1 results\"\n",
        "  \"formula 1 winner\"\n",
        "  \"formula one winner\"\n",
        "\n",
        "define bot refuse_off_topic\n",
        "  \"This assistant is designed for industrial crane operations. Please ask about installation, safety, or troubleshooting.\"\n",
        "\n",
        "define flow handle_off_topic\n",
        "  user ask_off_topic\n",
        "  bot refuse_off_topic\n",
        "\n",
        "# --- Crane-Related Q&A ---\n",
        "define user ask_crane_installation\n",
        "  \"How do I install the ceiling-mounted crane?\"\n",
        "  \"What are the steps to assemble the crane?\"\n",
        "  \"Can you guide me through the setup process?\"\n",
        "\n",
        "define bot respond_crane_installation\n",
        "  \"Installation of the ceiling-mounted crane involves several steps, including structural assessment, track assembly, and hoist installation. Let me fetch the exact procedure from the manual.\"\n",
        "\n",
        "define flow handle_crane_installation\n",
        "  user ask_crane_installation\n",
        "  bot respond_crane_installation\n",
        "  $answer = execute rag(query=$last_user_message)\n",
        "  bot $answer\n",
        "  bot \"Would you like more details on a specific step, such as electrical connections or load testing?\"\n",
        "\n",
        "# --- Maintenance & Safety ---\n",
        "define user ask_crane_maintenance\n",
        "  \"How do I perform regular maintenance?\"\n",
        "  \"What is the recommended maintenance schedule?\"\n",
        "  \"What lubrication should I use?\"\n",
        "  \"How often should I inspect the crane?\"\n",
        "\n",
        "define bot respond_crane_maintenance\n",
        "  \"Routine maintenance ensures the crane operates safely and efficiently. Let me retrieve the maintenance guidelines.\"\n",
        "\n",
        "define flow handle_crane_maintenance\n",
        "  user ask_crane_maintenance\n",
        "  bot respond_crane_maintenance\n",
        "  $answer = execute rag(query=$last_user_message)\n",
        "  bot $answer\n",
        "  bot \"Do you need specific details on inspections, lubrication, or troubleshooting common issues?\"\n",
        "\n",
        "# --- Load Capacity & Safety Warnings ---\n",
        "define user ask_crane_safety\n",
        "  \"What are the safety warnings?\"\n",
        "  \"What is the maximum load capacity?\"\n",
        "  \"Can I use this crane to lift people?\"\n",
        "  \"What safety checks should I do before operating the crane?\"\n",
        "\n",
        "define bot respond_crane_safety\n",
        "  \"Crane safety is critical. Overloading, improper rigging, or ignoring maintenance can cause failures. Let me check the manual for precise safety recommendations.\"\n",
        "\n",
        "define flow handle_crane_safety\n",
        "  user ask_crane_safety\n",
        "  bot respond_crane_safety\n",
        "  $answer = execute rag(query=$last_user_message)\n",
        "  bot $answer\n",
        "  bot \"Would you like additional information on operator training, emergency procedures, or regulatory compliance?\"\n",
        "\n",
        "# --- Troubleshooting & Error Codes ---\n",
        "define user ask_crane_troubleshooting\n",
        "  \"The crane is not moving\"\n",
        "  \"I hear a strange noise from the hoist\"\n",
        "  \"The motor is overheating\"\n",
        "  \"There is an error code on the control panel\"\n",
        "\n",
        "define bot respond_crane_troubleshooting\n",
        "  \"Let's troubleshoot the issue. Please describe the symptoms in more detail, or I can check the error code list.\"\n",
        "\n",
        "define flow handle_crane_troubleshooting\n",
        "  user ask_crane_troubleshooting\n",
        "  bot respond_crane_troubleshooting\n",
        "  $answer = execute rag(query=$last_user_message)\n",
        "  bot $answer\n",
        "  bot \"If the issue persists, I can provide troubleshooting steps or refer you to a certified technician.\"\n",
        "\n",
        "# --- Escalation for Other Industrial Topics ---\n",
        "define user ask_other_industrial_topic\n",
        "  \"How do I calibrate an industrial sensor?\"\n",
        "  \"What is the best way to inspect conveyor belts?\"\n",
        "  \"How do I optimize production line efficiency?\"\n",
        "  \"What are the best maintenance practices for hydraulic systems?\"\n",
        "\n",
        "define bot escalate_other_topic\n",
        "  \"Your question goes beyond crane operations. I will connect you with a more suitable system or expert.\"\n",
        "\n",
        "define flow handle_other_industrial_topic\n",
        "  user ask_other_industrial_topic\n",
        "  bot escalate_other_topic\n",
        "  $escalation_response = execute escalate_to_industrial_system(query=$last_user_message)\n",
        "  bot $escalation_response\n",
        "\n",
        "# --- Handling Repetitive / Clarification Requests ---\n",
        "define user ask_repeat_or_clarify\n",
        "  \"Can you explain that again?\"\n",
        "  \"I didn't understand, can you rephrase?\"\n",
        "  \"Could you give me more details?\"\n",
        "\n",
        "define flow handle_repeat\n",
        "  user ask_repeat_or_clarify\n",
        "  bot \"Certainly! Let me simplify the explanation...\"\n",
        "  $answer = execute rag(query=$last_user_message)\n",
        "  bot $answer\n",
        "\n",
        "# --- Unrecognized Queries ---\n",
        "define user ask_unclear_question\n",
        "  \"Hmmm...\"\n",
        "  \"I'm not sure how to ask\"\n",
        "  \"Can you help me with something else?\"\n",
        "\n",
        "define bot respond_unclear\n",
        "  \"Could you provide more details about what you need help with? I can assist with installation, maintenance, and troubleshooting.\"\n",
        "\n",
        "define flow handle_unclear_question\n",
        "  user ask_unclear_question\n",
        "  bot respond_unclear\n",
        "\n",
        "# --- Ending Message ---\n",
        "define user end_conversation\n",
        "  \"That’s all for now\"\n",
        "  \"Thank you\"\n",
        "  \"Goodbye\"\n",
        "  \"No, I don’t need more help\"\n",
        "\n",
        "define bot say_goodbye\n",
        "  \"You're welcome! If you need more help with crane operations, feel free to return anytime. Have a safe workday.\"\n",
        "\n",
        "define flow handle_goodbye\n",
        "  user end_conversation\n",
        "  bot say_goodbye\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p8hSFRaJoC5p"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc8wyV2DRQpa"
      },
      "source": [
        "#### Re-initialize Rails with Colang Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkWgd8CyRCqS"
      },
      "source": [
        "At this point, we can add Colang content for the conversation flows next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Sf3iJe6qRa5r"
      },
      "outputs": [],
      "source": [
        "config = RailsConfig.from_content(\n",
        "    yaml_content=yaml_content,\n",
        "    colang_content=colang_content\n",
        ")\n",
        "rails = LLMRails(config)\n",
        "\n",
        "# Re-register actions to ensure they're recognized\n",
        "rails.register_action(rag, \"rag\")\n",
        "rails.register_action(escalate_to_industrial_system, \"escalate_to_industrial_system\")\n",
        "#print(\"NeMo Guardrails configured successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfiUYh1bRdj3"
      },
      "source": [
        "###Testing & Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Na99GrssPRsT"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "n58xK_I1RYXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a4ff83-f199-4993-cc68-1db202914fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🟢 TEST 1: Crane-Related Question\n",
            "Bot: FARMA cranes, also known as forestry cranes, are primarily used in the forestry industry for tasks such as loading and unloading timber, moving logs, and assisting in forestry operations. These cranes are designed to be mounted on forestry trucks or trailers, allowing them to operate efficiently in rugged and forested environments.\n",
            "The primary applications of FARMA cranes include:\n",
            "1. Loading and unloading timber: FARMA cranes are used to lift logs and timber onto trucks for transportation.\n",
            "2. Moving logs: These cranes can handle and move logs within a forestry operation or processing facility.\n",
            "3. Assisting in forestry operations: FARMA cranes support various forestry tasks, such as clearing trees, handling forestry equipment, and assisting in forest management activities.\n",
            "Industries where FARMA cranes are commonly used include:\n",
            "1. Forestry industry: FARMA cranes are essential equipment for forestry companies, logging operations, and timber harvesting.\n",
            "2. Logging industry: These cranes play a crucial role in logging operations, including tree felling, log transportation, and timber processing.\n",
            "3. Wood processing industry: FARMA cranes are utilized in wood processing facilities for handling raw timber and assisting in the production process.\n",
            "Overall, FARMA cranes are versatile and reliable tools specifically designed to meet the demanding requirements of the forestry and related industries.\n",
            "\n",
            "\n",
            "🟡 TEST 2: Off-Topic Question\n",
            "Bot: This assistant is designed for industrial crane operations. Please ask about installation, safety, or troubleshooting.\n",
            "\n",
            "\n",
            "🟠 TEST 3: Industrial But Non-Crane Question (Escalation)\n",
            "[Escalation] Forwarding query to external industrial expert system: How do I calibrate an industrial sensor?\n",
            "Bot: Your question goes beyond crane operations. I will connect you with a more suitable system or expert.\n",
            "I have forwarded your request: 'How do I calibrate an industrial sensor?'. A specialist will assist you shortly.\n",
            "\n",
            "\n",
            "🔴 TEST 4: Ending Conversation\n",
            "Bot: You're welcome. If you have any more questions or need help with anything else, feel free to ask!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "async def demo_crane_assistant():\n",
        "    print(\"\\n🟢 TEST 1: Crane-Related Question\")\n",
        "    response = await rails.generate_async(prompt=\"What are the primary applications of FARMA cranes, and in which industries are they intended to be used?\")\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    print(\"\\n🟡 TEST 2: Off-Topic Question\")\n",
        "    response = await rails.generate_async(prompt=\"What's the best soccer team?\")\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    print(\"\\n🟠 TEST 3: Industrial But Non-Crane Question (Escalation)\")\n",
        "    response = await rails.generate_async(prompt=\"How do I calibrate an industrial sensor?\")\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "    print(\"\\n🔴 TEST 4: Ending Conversation\")\n",
        "    response = await rails.generate_async(prompt=\"Thank you\")\n",
        "    print(f\"Bot: {response}\\n\")\n",
        "\n",
        "try:\n",
        "    loop = asyncio.get_running_loop()\n",
        "    task = loop.create_task(demo_crane_assistant())\n",
        "    await task\n",
        "except RuntimeError:\n",
        "    asyncio.run(demo_crane_assistant())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}